<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <title>Ultra-fast WebGPU Voice (Whisper + Native TTS)</title>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>

  <style>
    :root{ --glass: rgba(0,0,0,.52); --blur: 12px; --radius: 16px; --accent:#3fb950; --muted:#c9c9c9; --danger:#e5534b; }
    *{ box-sizing:border-box; }
    html,body{ margin:0; height:100%; background:#0f1115; color:#fff; font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif; }
    .bg{ position:fixed; inset:0;
      background:
        radial-gradient(1200px 700px at 20% 20%, rgba(63,185,80,.16), transparent 60%),
        radial-gradient(900px 600px at 80% 40%, rgba(229,83,75,.10), transparent 55%),
        radial-gradient(1000px 800px at 50% 90%, rgba(120,160,255,.08), transparent 60%),
        #0f1115;
    }
    .topbar{ position:fixed; top:12px; left:16px; right:16px; display:flex; align-items:center; gap:10px; z-index:5; }
    .chip{ display:inline-flex; align-items:center; gap:8px; background:var(--glass); backdrop-filter:blur(var(--blur));
      border-radius:999px; padding:8px 12px; font-weight:800; box-shadow:0 4px 30px rgba(0,0,0,.25); }
    .dot{ width:8px; height:8px; border-radius:50%; background:var(--muted); }
    .spacer{ flex:1; }
    .btn{ border:none; color:#111; font-weight:900; cursor:pointer; padding:10px 14px; border-radius:999px; background:#c5c7cf; opacity:.92; }
    .btn.primary{ background:#b9f7c6; }
    .btn.danger{ background:#f0b6c0; }
    .btn:disabled{ opacity:.5; cursor:not-allowed; }

    #left{ position:fixed; left:24px; bottom:24px; display:flex; flex-direction:column; gap:14px; max-width:560px; z-index:4; }
    #right{ position:fixed; right:24px; bottom:24px; width:min(600px,46vw); display:flex; flex-direction:column; gap:14px; z-index:4; }

    .panel{ background:var(--glass); backdrop-filter:blur(var(--blur)); border-radius:var(--radius); padding:16px 18px; color:#fff;
      box-shadow:0 4px 30px rgba(0,0,0,.25); }
    .panel h4{ margin:0 0 10px 0; opacity:.92; letter-spacing:.2px; font-weight:950; }
    .small{ font-size:12px; opacity:.85; line-height:1.35; }
    .mono{ font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas, "Liberation Mono", monospace; }
    #log{ white-space:pre-wrap; max-height:22vh; overflow:auto; font-size:13px; opacity:.95; }
    .big{ font-size:16px; line-height:1.4; white-space:pre-wrap; }
    .row{ display:flex; gap:10px; align-items:center; flex-wrap:wrap; }
    .pill{ display:inline-flex; align-items:center; gap:8px; padding:6px 10px; border-radius:999px;
      border:1px solid rgba(255,255,255,.16); background:rgba(255,255,255,.06); font-weight:900; font-size:12px; opacity:.95; }

    input[type="range"]{ width:220px; }
    @media (max-width:900px){ #left{ max-width:420px; } #right{ width: calc(100vw - 48px);} }
  </style>

  <!-- transformers.js -->
  <script type="importmap">
  { "imports": { "@huggingface/transformers": "https://cdn.jsdelivr.net/npm/@huggingface/transformers@3.7.2" } }
  </script>
</head>

<body>
  <div class="bg"></div>

  <div class="topbar">
    <div class="chip"><span class="dot" id="gpuDot"></span> <span id="gpuLabel">WebGPU: checking…</span></div>
    <div class="chip"><span class="dot" id="micDot"></span> <span id="micLabel">Mic: idle</span></div>
    <div class="chip"><span class="dot" id="asrDot"></span> <span id="asrLabel">ASR: idle</span></div>
    <div class="chip"><span class="dot" id="ttsDot"></span> <span id="ttsLabel">TTS: idle</span></div>
    <div class="spacer"></div>
    <button id="initBtn" class="btn">Init</button>
    <button id="listenBtn" class="btn primary" disabled>Start</button>
    <button id="stopBtn" class="btn danger" disabled>Stop</button>
  </div>

  <div id="left">
    <div class="panel">
      <h4>Speed-first settings</h4>
      <div class="row">
        <span class="pill">ASR: <span class="mono">whisper-tiny.en</span></span>
        <span class="pill">TTS: <span class="mono">speechSynthesis</span></span>
        <span class="pill">Sample rate: <span class="mono">16kHz</span></span>
      </div>

      <div class="row" style="margin-top:12px">
        <span class="pill">Window <span class="mono" id="winLabel">0.8s</span></span>
        <input id="winRange" type="range" min="0.6" max="1.4" step="0.1" value="0.8">
        <span class="pill">Step <span class="mono" id="stepLabel">300ms</span></span>
        <input id="stepRange" type="range" min="200" max="900" step="50" value="300">
      </div>

      <div class="row" style="margin-top:12px">
        <span class="pill">Finalize silence <span class="mono" id="silLabel">650ms</span></span>
        <input id="silRange" type="range" min="350" max="1400" step="50" value="650">
        <span class="pill">VAD thresh <span class="mono" id="vadLabel">0.015</span></span>
        <input id="vadRange" type="range" min="0.006" max="0.05" step="0.001" value="0.015">
      </div>

      <div class="small" style="margin-top:10px">
        This is “streaming-ish”: it runs Whisper every step on the most recent audio window and updates partial text quickly.
        When you pause speaking, it finalizes and speaks a response. This build fixes the “Float32Array vs Object” Whisper input bug.
      </div>
    </div>

    <div class="panel">
      <h4>Debug Log</h4>
      <div id="log" class="mono">Ready.</div>
    </div>
  </div>

  <div id="right">
    <div class="panel">
      <h4>Live transcript</h4>
      <div id="live" class="big">—</div>
      <div class="small">Updates while you speak.</div>
      <div class="small mono" id="typeLine" style="margin-top:8px; opacity:.75">ASR input: —</div>
    </div>
    <div class="panel">
      <h4>Assistant reply</h4>
      <div id="reply" class="big">—</div>
      <div class="small">Spoken immediately using the OS voice.</div>
    </div>
  </div>

<script type="module">
import { pipeline, env } from "@huggingface/transformers";

const $ = (id) => document.getElementById(id);
const logEl = $("log");
const liveEl = $("live");
const replyEl = $("reply");
const typeLine = $("typeLine");

const gpuDot = $("gpuDot"), gpuLabel = $("gpuLabel");
const micDot = $("micDot"), micLabel = $("micLabel");
const asrDot = $("asrDot"), asrLabel = $("asrLabel");
const ttsDot = $("ttsDot"), ttsLabel = $("ttsLabel");

const initBtn = $("initBtn");
const listenBtn = $("listenBtn");
const stopBtn = $("stopBtn");

const winRange = $("winRange");
const stepRange = $("stepRange");
const silRange = $("silRange");
const vadRange = $("vadRange");
const winLabel = $("winLabel");
const stepLabel = $("stepLabel");
const silLabel = $("silLabel");
const vadLabel = $("vadLabel");

function log(msg) {
  const t = new Date().toLocaleTimeString();
  logEl.textContent = `[${t}] ${msg}\n` + logEl.textContent;
}
function dot(dotEl, on) { dotEl.style.background = on ? "#3fb950" : "#c9c9c9"; }
function setGPU(ok){ dot(gpuDot, ok); gpuLabel.textContent = ok ? "WebGPU: available" : "WebGPU: not available"; }
function setMic(on){ dot(micDot, on); micLabel.textContent = on ? "Mic: capturing" : "Mic: idle"; }
function setASR(state){ dot(asrDot, state !== "idle"); asrLabel.textContent = `ASR: ${state}`; }
function setTTS(state){ dot(ttsDot, state !== "idle"); ttsLabel.textContent = `TTS: ${state}`; }

const webgpuOK = ("gpu" in navigator);
setGPU(webgpuOK);

env.allowLocalModels = false;

let asr = null;

// ---------- Speed knobs (live adjustable) ----------
const TARGET_SR = 16000;
let WINDOW_SEC = parseFloat(winRange.value);
let STEP_MS = parseInt(stepRange.value, 10);
let SILENCE_MS_TO_FINAL = parseInt(silRange.value, 10);
let VAD_THRESH = parseFloat(vadRange.value);

function syncKnobs(){
  WINDOW_SEC = parseFloat(winRange.value);
  STEP_MS = parseInt(stepRange.value, 10);
  SILENCE_MS_TO_FINAL = parseInt(silRange.value, 10);
  VAD_THRESH = parseFloat(vadRange.value);

  winLabel.textContent = `${WINDOW_SEC.toFixed(1)}s`;
  stepLabel.textContent = `${STEP_MS}ms`;
  silLabel.textContent = `${SILENCE_MS_TO_FINAL}ms`;
  vadLabel.textContent = `${VAD_THRESH.toFixed(3)}`;

  // If running, resize ring buffer (safe reset)
  if (running) {
    log("Knobs changed; resetting buffers.");
    resetRing();
  }
}
winRange.oninput = syncKnobs;
stepRange.oninput = () => { syncKnobs(); if (running) restartTimer(); };
silRange.oninput = syncKnobs;
vadRange.oninput = syncKnobs;
syncKnobs();

// ---------- Audio capture ----------
let audioCtx = null;
let workletNode = null;
let micStream = null;

let ring = null;
let ringWrite = 0;
let haveSamples = 0;

let lastHeardAt = 0;
let lastPartial = "";
let running = false;
let stepTimer = null;
let inFlight = false;
let speaking = false;

function resetRing(){
  ring = new Float32Array(Math.ceil(TARGET_SR * WINDOW_SEC));
  ringWrite = 0;
  haveSamples = 0;
  lastHeardAt = 0;
  lastPartial = "";
  liveEl.textContent = "—";
  replyEl.textContent = "—";
  typeLine.textContent = "ASR input: —";
}

resetRing();

function rms(buf) {
  let s = 0;
  for (let i = 0; i < buf.length; i++) s += buf[i]*buf[i];
  return Math.sqrt(s / buf.length);
}

// ALWAYS return Float32Array
function getWindow() {
  const len = ring.length;
  const out = new Float32Array(len);
  const start = (ringWrite - len + ring.length) % ring.length;
  for (let i = 0; i < len; i++) out[i] = ring[(start + i) % ring.length];
  return out;
}

function stopAllSpeech() {
  try { speechSynthesis.cancel(); } catch {}
  speaking = false;
  setTTS("idle");
}

function speakFast(text) {
  stopAllSpeech();
  if (!text) return;

  const u = new SpeechSynthesisUtterance(text);
  u.rate = 1.12;
  u.pitch = 1.0;
  u.volume = 1.0;

  const voices = speechSynthesis.getVoices?.() || [];
  const v = voices.find(v => /en-US|en_US|English/i.test(v.lang || v.name)) || voices[0];
  if (v) u.voice = v;

  u.onstart = () => { speaking = true; setTTS("speaking"); };
  u.onend = () => { speaking = false; setTTS("idle"); };
  u.onerror = () => { speaking = false; setTTS("idle"); };

  speechSynthesis.speak(u);
}

// Ultra-fast “brain” (no LLM)
function respond(text) {
  const t = (text || "").trim();
  if (!t) return "I didn’t catch that.";
  const low = t.toLowerCase();

  if (low.includes("hello") || low.includes("hey")) return "Hey. What’s up?";
  if (low.includes("time")) return `It’s ${new Date().toLocaleTimeString()}.`;
  if (low.includes("stop")) return "Okay. Stopping.";
  if (low.includes("weather")) return "Tell me your city for weather.";

  // keep it short & snappy
  if (t.length <= 70) return `Got it: ${t}`;
  return "Got it.";
}

async function initModels() {
  initBtn.disabled = true;
  try {
    setASR("loading…");
    asr = await pipeline(
      "automatic-speech-recognition",
      "onnx-community/whisper-tiny.en",
      { device: webgpuOK ? "webgpu" : "wasm" }
    );
    setASR("ready");
    log("ASR ready (whisper-tiny.en).");

    // warm voices
    try { speechSynthesis.getVoices(); } catch {}
    setTTS("idle");

    listenBtn.disabled = false;
    stopBtn.disabled = false;
  } catch (e) {
    log("Init error: " + (e?.message || e));
    initBtn.disabled = false;
    setASR("idle");
  }
}

async function ensureAudioWorklet() {
  if (audioCtx) return;

  audioCtx = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: TARGET_SR });

  const code = `
    class Capture extends AudioWorkletProcessor {
      process(inputs) {
        const input = inputs[0];
        if (input && input[0]) this.port.postMessage(input[0].slice(0));
        return true;
      }
    }
    registerProcessor('capture', Capture);
  `;
  const url = URL.createObjectURL(new Blob([code], { type: "application/javascript" }));
  await audioCtx.audioWorklet.addModule(url);
  URL.revokeObjectURL(url);

  workletNode = new AudioWorkletNode(audioCtx, "capture");
  workletNode.port.onmessage = (e) => {
    if (!running) return;
    const frame = e.data; // Float32Array

    // write to ring buffer
    for (let i = 0; i < frame.length; i++) {
      ring[ringWrite] = frame[i];
      ringWrite = (ringWrite + 1) % ring.length;
    }
    haveSamples = Math.min(ring.length, haveSamples + frame.length);

    // VAD energy threshold
    if (rms(frame) > VAD_THRESH) lastHeardAt = performance.now();
  };

  log("AudioWorklet ready @16kHz.");
}

function restartTimer(){
  if (stepTimer) { clearInterval(stepTimer); stepTimer = null; }
  if (running) stepTimer = setInterval(tick, STEP_MS);
}

async function start() {
  if (!asr) return;
  if (running) return;

  await ensureAudioWorklet();
  if (audioCtx.state !== "running") await audioCtx.resume();

  micStream = await navigator.mediaDevices.getUserMedia({
    audio: { echoCancellation:true, noiseSuppression:true, autoGainControl:true }
  });

  const source = audioCtx.createMediaStreamSource(micStream);
  source.connect(workletNode);

  resetRing();

  running = true;
  setMic(true);
  setASR("listening…");
  log("Started.");
  restartTimer();
}

async function stop() {
  running = false;

  // IMPORTANT: clear timer first to stop ASR calls immediately
  if (stepTimer) { clearInterval(stepTimer); stepTimer = null; }

  setMic(false);
  setASR("idle");
  stopAllSpeech();

  try { if (micStream) micStream.getTracks().forEach(t => t.stop()); } catch {}
  micStream = null;

  log("Stopped.");
}

async function tick() {
  if (!running || inFlight || speaking) return;
  if (!ring || haveSamples < ring.length) return; // need full window

  inFlight = true;
  try {
    setASR("decoding…");

    const windowAudio = getWindow(); // Float32Array guaranteed
    typeLine.textContent = `ASR input: ${windowAudio.constructor.name} len=${windowAudio.length}`;

    // ✅ Correct transformers.js signature: audio array first, options second
    const result = await asr(windowAudio, { sampling_rate: TARGET_SR });

    const text = (result?.text || "").trim();

    if (text && text !== lastPartial) {
      lastPartial = text;
      liveEl.textContent = text;
    }

    const now = performance.now();
    const quietLongEnough = lastHeardAt && (now - lastHeardAt) > SILENCE_MS_TO_FINAL;

    if (quietLongEnough && lastPartial && lastPartial.length >= 6) {
      const finalText = lastPartial;
      log("Final: " + finalText);

      const r = respond(finalText);
      replyEl.textContent = r;
      speakFast(r);

      // reset for next utterance
      lastPartial = "";
      liveEl.textContent = "—";
      lastHeardAt = 0;
    }

    setASR("listening…");
  } catch (e) {
    log("ASR error: " + (e?.message || e));
    setASR("listening…");
  } finally {
    inFlight = false;
  }
}

initBtn.onclick = initModels;
listenBtn.onclick = start;
stopBtn.onclick = stop;

window.addEventListener("beforeunload", () => { try{ stop(); }catch{} });

log("Click Init, then Start.");
</script>
</body>
</html>
